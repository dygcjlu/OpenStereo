data_cfg:
  #name: KITTI2015
  #root: data/kitti15
  #train_list: datasets/KITTI15/kitti15_train200.txt
  #val_list: datasets/KITTI15/kitti15_train200.txt
  #test_list: datasets/KITTI15/kitti15_test.txt
#  name: KITTI2012
#  root: data/kitti12
#  train_list: datasets/KITTI12/kitti12_train194.txt
#  val_list: datasets/KITTI12/kitti12_train194.txt
#  test_list: datasets/KITTI12/kitti12_test.txt
  name: custom
  root: /data/dyg/dataset/custom/hk/20240424/
  train_list: /data/dyg/dataset/custom/hk/20240424/train.txt
  val_list: /data/dyg/dataset/custom/hk/20240424/val.txt
  test_list: /data/dyg/dataset/custom/hk/20240424/val.txt

  batch_uniform: false
  num_workers: 8
  train_batch_size: 2
  val_batch_size: 1
  #  random_type: range
  #  w_range: [ 0.5, 2.0 ]
  #  h_range: [ 0.5, 2.0 ]
  #  random_type: choice
  #  h_range: [ 256, 288, 320, 352 ]
  #  w_range: [ 480, 512, 544, 576 ]  [ 480, 864 ]

  transform:
    train:
      - type: RandomCrop
        size: [ 320, 864 ]
      - type: GetValidDisp
        max_disp: 48
      - type: TransposeImage
      - type: ToTensor
      - type: NormalizeImage
        mean: [ 0.45669437, 0.39147964, 0.3354694 ]
        std: [ 0.17762711, 0.19345888, 0.18680351 ]
    val:
      - type: CropOrPad
        size: [ 528, 960 ]
      - type: GetValidDisp
        max_disp: 48
      - type: TransposeImage
      - type: ToTensor
      - type: NormalizeImage
        mean: [ 0.45669437, 0.39147964, 0.3354694 ]
        std: [ 0.17762711, 0.19345888, 0.18680351 ]
    test:
      - type: CropOrPad
        size: [ 528, 960 ]
      - type: TransposeImage
      - type: ToTensor
      - type: NormalizeImage
        mean: [ 0.45669437, 0.39147964, 0.3354694 ]
        std: [ 0.17762711, 0.19345888, 0.18680351 ]


model_cfg:
  model: MSNet
  model_type: 2D

  base_config:
    max_disp: 48

loss_cfg:
  - log_prefix: disp
    loss_term_weight: 1
    type: Weighted_Smooth_l1_Loss
    weights: [ 0.5, 0.5, 0.7, 1.0 ]


trainer_cfg:
  save_name: MSNet2D_SceneFlow
  total_epoch: 20
  restore_hint: 0
  optimizer_reset: false
  scheduler_reset: false
  warmup_reset: false
  log_iter: 50 # iter
  save_every: 1 # epoch
  val_every: 1 # epoch
  amp: false
  sync_bn: false
  fix_bn: false
  init_parameters: false

  optimizer_cfg:
    solver: Adam
    lr: 0.001
    betas: [ 0.9, 0.999 ]

  scheduler_cfg:
    scheduler: MultiStepLR
    gamma: 0.5
    milestones: [ 10, 12, 14, 16 ]
    warmup:
      warmup_steps: 100

  evaluator_cfg:
    metric:
      - d1_all
      - epe
      - bad_1
      - bad_2
      - bad_3

#  clip_grad_cfg:
#    #    type: norm
#    #    max_norm: 35
#    #    norm_type: 2
#    type: value
#    clip_value: 0.1